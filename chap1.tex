\chapter{Cadenas de Markov}



Una cadena de Markov es una sucesi\'on de ensayos similares u observaciones en la cual cada ensayo tiene el mismo n\'umero finito de resultados posibles y en donde la probabilidad de cada resultado para un ensayo dado depende s\'olo del resultado del ensayo inmediatamente precedente y no de cualquier resultado previo.


\section{Cadenas de Markov Homogenea}

Sea una matriz $k x k$ y $P = (p_i,_j)$ un proceso aleatorio $(X_0,X_1,...)$ con un espacio finito $S = \{s_1,s_2,...,s_k\}$ $ Im X_0 \cup Im X_1 \cup ImX_2$... se dice que es una CADENA DE MARKOV HOMOGENEA CON MATRIZ de transici\'on P, si $\forall n$ y $\forall i,j \epsilon \{1,...,k\} $ se tiene $P(X_{n +1} = s_j | X_0 = s_i,..., X_n = s_i$\\
$ P (X_{n+1} = s_j | X_n = s_i) = p_{ij}$


Distribuci\'on de probabilidad :
$\sum_{j = 1}^{k}p_{i,j} = \sum_{j = 1}^k p(X_{n +1} = j | X_n = i) = 1$


%definicion 

% forma

