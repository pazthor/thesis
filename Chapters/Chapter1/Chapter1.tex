% Capitulo 1: caminatas aleatorias
\chapter{Probabilidad Caminatas aleatorias cadenas de  Markov}
% Write in your own chapter title
\label{Chapter1}
\lhead{Cap\'itulo 1.\emph{Caminatas aleatorias}} % Write in your own
% chapter title to
% set the page
% header


\section {\textquestiondown Qu\'e son las caminatas aleatorias ?}
Una caminata aleatoria es una serie de pasos donde la decisi\'on de
elegir una caminata aleatoria es una serie de pasos que no dependa del
paso anterior o en donde el caminante se encuentre en ese momento,
cada paso es una decision al azar y \"estocastica\", en computacion
existen varias 'estrategias' que ayudan a implementar la aleatoriedad
de cada paso que da un caminante como son 'metropolis hasting'\todo{falta definir texto}
'movimiento brownianno', 'vuelo de levy'.\\

Por ejemplo una caminanata aleatoria se puede considerar como los
movimientos que realiza una persona en estado ebriedad, el cual pierde
el control en sus movimientos de tal manera que cada movimiento que
realize sera imcomprensible y complicado de predecir.






\section{Probabilidad y concepto b\'asicos}
En esta seccion vamos a escribir los temas que fuesen necesarios para
comprender caminatas aleatorias empezando por conceptos de
probabilidad, variable aleatoria, caminatas aleatorias y por cadenas
de markov.


\subsection{Cadenas de Markov}
Una cadena de Markov es una sucesi\'on de ensayos similares u
observaciones en la cual cada ensayo tiene el mismo n\'umero finito de
resultados posibles y en donde la probabilidad de cada resultado para
un ensayo dado depende s\'olo del resultado del ensayo inmediatamente
precedente y no de cualquier resultado previo.


Una cadena de markov es una suecison de variables aleatorias las
cuales dependen de la anterio



\subsubsection{cadenas de markov homogenea}

Sea una matriz $k \times k$ y $P = (p_i,_j)$. Un proceso aleatorio
$(X_0,X_1,...)$ con espacio finito de estados
$S = \{s_1,s_2,...,s_k\}= im \, x_0 \; \cup im x_1 \cup imx_2, \ldots$
se dice que es una \emph{cadena de markov homogenea con matriz de
transici\'on} $P$, si $\forall n$ y
$\forall i,j \epsilon \{1,\ldots,k\} $ se tiene
\[p(x_{n +1} = s_j | x_0 = s_i,\dots, x_n = s_i) = p (x_{n+1} = s_j |
  x_n = s_i) = p_{ij}\]
$p(x_{n + 1} = s_{_i} |x_n = s_i )$
$p(x_{n+1} = s_i | X _n = s_i) $ .... etc (sigue asi) Homogeneiddad en
el tiempo <Agregar llave para indicarlo>

Hay que notar que $P_{i,j} >= 0$<cambiar a simbolo mayor o igual > y
que $\sum_{j=1}^{k}P_{ji} = 1$

Lo anterior se traduce a una distribuci\'on de probabilidad:
$$\sum_{j = 1}^{k}p_{i,j} = \sum_{j = 1}^k p(X_{n +1} = j | X_n = i) =
1$$

\todo[fancyline]{resaltar} Definici\'on: La distribuci\'on inicial de
la cadena de Markov Hom\'ogenea Sea $(X_0,X_1,...) $ una variable
aleatoria

<agregar una conexi\'on > es
$\mu^{(0)} = (p(X_0 = s_1), p(X_0 = s_2) ...p(X_0 = s_k))$
$ = ( \mu_1^0, \mu_2^{(0)},\mu_3^{(0)} ... \mu_k^{(0)}) $

<agregar estilo a lo siguiente.> Ejemplo:
$\mu^{(0)} (p(X_0 = 1), p(X_0 = 2)) $
$= (1, 0, 0, 0)p(X_0 = 3), p(X_0 = 4)$

Distribuci\'on en el tiempo $n$:

$\mu^{(n)} = (p(X_n = s_i), p(X_n = s_2), ..., p(X_n = s_k))$
\todo[inline]{fue otra sesion y se agrega otro ejemplo el borracho de
  las 4 esquinas }
$\mu^{(n)} = (p(X_n = s_i),p(X_n = s_2) ... p(X_n = s_k))$
$= (\mu_1^{(n)}, \mu_2^{(n)}, ..., \mu_k^{(n)} )$





\todo{16 de Mayo}
$\mu^{(1)} = (p(X_1 = 1), p(X_1 = 2), p(X_1 = 3), p(X_1 = 4)$
$ = (0, 1/2, 0, 1/2) $

Teorema\todo{Resaltar} Sea $(X_0, X_1, X_2, X_3, . )$ una cadena de
Markov con espacios de estados finitos $\{s_1,s_2,...,s_k\}$ y
distribuci\'on inicial $\mu^{(0)}$. Entonces\\

$\mu = \mu^{0}P^n_2 $ $P$ es una matriz cuadrada \todo{poner x de por
  existe} $k xk $, $k$ es el
n\'umero de elementos de estados finitos.\\



Demostraci\'on por inducci\'on n
\begin{equation}\label{eq1:ej1}
  n = 0
  \mu^{(0)} = \mu^{(0)} P^{(0)}
  n = 1
  \mu^{(1)}_j = p(X = s_j)
  = p(X_0 = s_1, X_1 = s_j)
  +
  p(X_0 = s_2, X_1 = s_j
  .
  .
  .
  + p(X_0 = s_k, X_1 = s_j)
  =\sum^{k}_{i = 1} p(X_0 = s_i, X_1 = s_j)\\
  =\sum^{k}_{i = 1} p(X_1 = s_i, X_0 = s_j\\
  =\sum^n_{i = 1} p(X_0 = s_i,) p(X_1 = s_j | X_0 = s_i )\\
  => \mu^{(0)} = \mu^{(1)}P
\end{equation}\todo[fancyline]{colocar ecuaciones }


\todo[inline]{18 de mayo} $\mu^{(n)} = \mu^{(n)}P^n$

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../Tesis"
%%% End:
